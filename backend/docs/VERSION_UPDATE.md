# ä¾èµ–ç‰ˆæœ¬æ›´æ–°è¯´æ˜

## æ›´æ–°æ¦‚è¿°

å·²å°†æ‰€æœ‰ä¾èµ–æ›´æ–°åˆ°æœ€æ–°ç¨³å®šç‰ˆæœ¬ï¼Œç‰¹åˆ«æ˜¯ LangChain å’Œ LangGraph ç”Ÿæ€ç³»ç»Ÿã€‚

## ä¸»è¦ç‰ˆæœ¬å˜æ›´

### AI æ¡†æ¶ (é‡å¤§æ›´æ–°)

| åŒ…å | æ—§ç‰ˆæœ¬ | æ–°ç‰ˆæœ¬ | å˜æ›´è¯´æ˜ |
|------|--------|--------|----------|
| langchain | 0.1.20 | **1.1.0** | ğŸ‰ é‡å¤§ç‰ˆæœ¬å‡çº§åˆ° 1.xï¼Œç”Ÿäº§å°±ç»ªï¼ |
| langchain-core | - | **1.1.0** | æ–°å¢æ ¸å¿ƒåŒ…ï¼Œ1.x ç¨³å®šç‰ˆ |
| langchain-community | - | **1.1.0** | æ–°å¢ç¤¾åŒºé›†æˆåŒ…ï¼Œ1.x ç¨³å®šç‰ˆ |
| langgraph | 0.0.40 | **1.0.4** | ğŸ‰ é‡å¤§ç‰ˆæœ¬å‡çº§åˆ° 1.xï¼ŒAPI ç¨³å®šï¼ |
| langchain-openai | 0.1.0 | **1.1.0** | ç‹¬ç«‹åŒ…ï¼Œ1.x ç¨³å®šç‰ˆ |
| chromadb | 0.4.22 | **0.5.23** | æ€§èƒ½æ”¹è¿› |
| openai | 1.12.0 | **1.58.1** | æœ€æ–° API æ”¯æŒ |

### Web æ¡†æ¶

| åŒ…å | æ—§ç‰ˆæœ¬ | æ–°ç‰ˆæœ¬ |
|------|--------|--------|
| fastapi | 0.104.1 | **0.109.0** |
| uvicorn | 0.24.0 | **0.27.0** |
| pydantic | 2.5.0 | **2.5.3** |

### æ•°æ®åº“

| åŒ…å | æ—§ç‰ˆæœ¬ | æ–°ç‰ˆæœ¬ |
|------|--------|--------|
| sqlalchemy | 2.0.23 | **2.0.25** |
| alembic | 1.12.1 | **1.13.1** |

### æµ‹è¯•

| åŒ…å | æ—§ç‰ˆæœ¬ | æ–°ç‰ˆæœ¬ |
|------|--------|--------|
| pytest | 7.4.3 | **8.0.0** |
| hypothesis | 6.92.1 | **6.98.3** |

## LangChain 1.x ä¸»è¦å˜æ›´ï¼ˆç”Ÿäº§å°±ç»ªï¼ï¼‰

### 1. æ¨¡å—åŒ–æ¶æ„ï¼ˆ1.x ç¨³å®šç‰ˆï¼‰

```python
# æ—§ç‰ˆæœ¬ (0.1.x)
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings

# æ–°ç‰ˆæœ¬ (1.x) - æ›´æ¸…æ™°çš„æ¨¡å—åˆ†ç¦»ï¼ŒAPI ç¨³å®š
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.vectorstores import Chroma
```

**é‡è¦**: 1.x ç‰ˆæœ¬æ ‡å¿—ç€ API ç¨³å®šï¼Œä¸ä¼šæœ‰ç ´åæ€§å˜æ›´ï¼

### 2. æ”¹è¿›çš„ç±»å‹å®‰å…¨

- å®Œå…¨æ”¯æŒ Pydantic v2
- æ›´å¥½çš„ç±»å‹æç¤º
- è¿è¡Œæ—¶ç±»å‹æ£€æŸ¥

### 3. ç»Ÿä¸€çš„ Runnable æ¥å£

æ‰€æœ‰ç»„ä»¶éƒ½å®ç° `Runnable` æ¥å£ï¼š
- `invoke()` - åŒæ­¥è°ƒç”¨
- `ainvoke()` - å¼‚æ­¥è°ƒç”¨
- `stream()` - æµå¼è¾“å‡º
- `astream()` - å¼‚æ­¥æµå¼è¾“å‡º
- `batch()` - æ‰¹é‡å¤„ç†

### 4. æ”¹è¿›çš„è¾“å‡ºè§£æ

```python
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel

class MyOutput(BaseModel):
    field1: str
    field2: int

parser = JsonOutputParser(pydantic_object=MyOutput)
chain = prompt | llm | parser
```

## LangGraph 1.x ä¸»è¦å˜æ›´ï¼ˆç”Ÿäº§å°±ç»ªï¼ï¼‰

### 1. ç¨³å®šçš„ APIï¼ˆ1.x ç‰ˆæœ¬ï¼‰

- ä» 0.0.x åˆ° **1.0.x**ï¼ŒAPI å®Œå…¨ç¨³å®š
- **ç”Ÿäº§ç¯å¢ƒå°±ç»ª**ï¼Œå¤§è§„æ¨¡åº”ç”¨éªŒè¯
- å‘åå…¼å®¹ä¿è¯

### 2. æ”¹è¿›çš„çŠ¶æ€ç®¡ç†

```python
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages

class State(TypedDict):
    messages: Annotated[list, add_messages]  # è‡ªåŠ¨åˆå¹¶æ¶ˆæ¯
    data: dict
```

### 3. æ–°çš„å›¾æ„å»º API

```python
from langgraph.graph import StateGraph, START, END

workflow = StateGraph(State)
workflow.add_node("node1", func1)
workflow.add_edge(START, "node1")
workflow.add_edge("node1", END)
app = workflow.compile()
```

### 4. æ¡ä»¶è¾¹æ”¯æŒ

```python
def should_continue(state):
    return "continue" if state["count"] < 10 else "end"

workflow.add_conditional_edges(
    "node1",
    should_continue,
    {
        "continue": "node2",
        "end": END
    }
)
```

## ChromaDB 0.5.x ä¸»è¦å˜æ›´

### 1. æ€§èƒ½æ”¹è¿›

- æ›´å¿«çš„å‘é‡æœç´¢
- ä¼˜åŒ–çš„å†…å­˜ä½¿ç”¨
- æ”¹è¿›çš„æŒä¹…åŒ–

### 2. æ–°çš„ API

```python
from langchain_community.vectorstores import Chroma

vectorstore = Chroma(
    collection_name="my_collection",
    embedding_function=embeddings,
    persist_directory="./chroma_db"
)

# æ·»åŠ æ–‡æ¡£
vectorstore.add_documents(documents)

# æœç´¢
results = vectorstore.similarity_search(query, k=5)

# å¸¦è¿‡æ»¤çš„æœç´¢
results = vectorstore.similarity_search(
    query,
    k=5,
    filter={"type": "plan"}
)
```

## OpenAI 1.58.x ä¸»è¦å˜æ›´

### 1. æ–°çš„ Embeddings æ¨¡å‹

```python
from langchain_openai import OpenAIEmbeddings

# æ¨èä½¿ç”¨æ–°æ¨¡å‹
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small"  # æ›´å¿«æ›´ä¾¿å®œ
    # model="text-embedding-3-large"  # æ›´é«˜è´¨é‡
)
```

### 2. æ”¹è¿›çš„ Chat æ¨¡å‹

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-4-turbo-preview",  # æœ€æ–°æ¨¡å‹
    temperature=0.7,
    streaming=True  # æ”¯æŒæµå¼è¾“å‡º
)
```

## è¿ç§»æŒ‡å—

### æ­¥éª¤ 1: æ›´æ–°ä¾èµ–

```bash
cd backend
pip install -r requirements.txt
```

### æ­¥éª¤ 2: æ›´æ–°å¯¼å…¥è¯­å¥

å°†æ‰€æœ‰æ—§çš„å¯¼å…¥æ›¿æ¢ä¸ºæ–°çš„æ¨¡å—åŒ–å¯¼å…¥ï¼š

```python
# æ›¿æ¢è¿™äº›
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma

# ä¸ºè¿™äº›
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
```

### æ­¥éª¤ 3: æ›´æ–° LangGraph ä»£ç 

```python
# æ—§ç‰ˆæœ¬
from langgraph.graph import StateGraph, END

# æ–°ç‰ˆæœ¬
from langgraph.graph import StateGraph, START, END

# ä½¿ç”¨ START è€Œä¸æ˜¯ set_entry_point
workflow.add_edge(START, "first_node")
```

### æ­¥éª¤ 4: æµ‹è¯•

è¿è¡Œæ‰€æœ‰æµ‹è¯•ç¡®ä¿å…¼å®¹æ€§ï¼š

```bash
pytest tests/ -v
```

## æ–°åŠŸèƒ½ç¤ºä¾‹

### 1. æµå¼è¾“å‡º

```python
async def stream_response(query: str):
    chain = prompt | llm
    async for chunk in chain.astream({"input": query}):
        yield chunk.content
```

### 2. ç»“æ„åŒ–è¾“å‡º

```python
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel

class Plan(BaseModel):
    meals: list
    exercises: list

parser = JsonOutputParser(pydantic_object=Plan)
chain = prompt | llm | parser
result = chain.invoke({"input": "ç”Ÿæˆè®¡åˆ’"})
```

### 3. å·¥å…·ä½¿ç”¨

```python
from langchain_core.tools import tool

@tool
def search_plans(query: str) -> list:
    """æœç´¢å†å²è®¡åˆ’"""
    return vectorstore.similarity_search(query)

tools = [search_plans]
agent = create_openai_tools_agent(llm, tools, prompt)
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ä½¿ç”¨ç¼“å­˜

```python
from langchain.cache import SQLiteCache
from langchain.globals import set_llm_cache

set_llm_cache(SQLiteCache(database_path=".langchain.db"))
```

### 2. æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡å‘é‡åŒ–
texts = ["text1", "text2", "text3"]
embeddings_list = embeddings.embed_documents(texts)
```

### 3. å¼‚æ­¥è°ƒç”¨

```python
# ä½¿ç”¨å¼‚æ­¥æé«˜æ€§èƒ½
result = await llm.ainvoke("query")
```

## æ³¨æ„äº‹é¡¹

1. **ç ´åæ€§å˜æ›´**: LangChain 0.3.x æœ‰ä¸€äº›ç ´åæ€§å˜æ›´ï¼Œéœ€è¦æ›´æ–°ä»£ç 
2. **æµ‹è¯•**: æ›´æ–°ååŠ¡å¿…è¿è¡Œå®Œæ•´çš„æµ‹è¯•å¥—ä»¶
3. **æ–‡æ¡£**: å‚è€ƒæœ€æ–°çš„å®˜æ–¹æ–‡æ¡£
4. **æ€§èƒ½**: æ–°ç‰ˆæœ¬æ€§èƒ½æ›´å¥½ï¼Œä½†éœ€è¦è°ƒæ•´é…ç½®

## å‚è€ƒèµ„æº

- [LangChain 0.3 è¿ç§»æŒ‡å—](https://python.langchain.com/docs/versions/migrating_chains/)
- [LangGraph æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [ChromaDB æ–‡æ¡£](https://docs.trychroma.com/)
- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs/)

## æ€»ç»“

è¿™æ¬¡æ›´æ–°å¸¦æ¥äº†ï¼š
- âœ… æ›´ç¨³å®šçš„ API
- âœ… æ›´å¥½çš„æ€§èƒ½
- âœ… æ›´å¼ºçš„ç±»å‹å®‰å…¨
- âœ… æ›´ä¸°å¯Œçš„åŠŸèƒ½
- âœ… æ›´å¥½çš„å¼€å‘ä½“éªŒ

å»ºè®®å°½å¿«è¿ç§»åˆ°æ–°ç‰ˆæœ¬ä»¥è·å¾—è¿™äº›æ”¹è¿›ã€‚
